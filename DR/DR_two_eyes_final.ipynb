{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMT545tczQwa"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from random import sample \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import copy\n",
    "import warnings\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Images from dataset\n",
    "Check the readme file to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAVA3Cuk08JG"
   },
   "outputs": [],
   "source": [
    "in_imgs_path = [] # Saves the path of images\n",
    "in_imgs = [] # Saves the name of images\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./data/train_data\"):\n",
    "    for filename in filenames:\n",
    "        in_imgs_path.append(os.path.join(dirname, filename))\n",
    "        in_imgs.append(filename[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(in_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unuseful columns from csv\n",
    "\n",
    "new_lbls_0 = pd.read_csv(\"./data/df0.csv\")\n",
    "new_lbls_0 = new_lbls_0.drop(columns=['path', 'level_cat','exists','PatientId','Unnamed: 0'])\n",
    "\n",
    "new_lbls_1 = pd.read_csv(\"./data/df1.csv\")\n",
    "new_lbls_1 = new_lbls_1.drop(columns=['path', 'level_cat','exists','PatientId','Unnamed: 0'])\n",
    "\n",
    "new_lbls_2 = pd.read_csv(\"./data/df2.csv\")\n",
    "new_lbls_2 = new_lbls_2.drop(columns=['path', 'level_cat','exists','PatientId','Unnamed: 0'])\n",
    "\n",
    "new_lbls_3 = pd.read_csv(\"./data/df3.csv\")\n",
    "new_lbls_3 = new_lbls_3.drop(columns=['path', 'level_cat','exists','PatientId','Unnamed: 0'])\n",
    "\n",
    "new_lbls_4 = pd.read_csv(\"./data/df4.csv\")\n",
    "new_lbls_4 = new_lbls_4.drop(columns=['path', 'level_cat','exists','PatientId','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Dataset into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lbls = pd.concat([new_lbls_0, new_lbls_1, new_lbls_2, new_lbls_3, new_lbls_4], ignore_index=True)\n",
    "display(in_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_lbls = in_lbls[in_lbls[\"eye\"] == 1]\n",
    "display(left_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_lbls = in_lbls[in_lbls[\"eye\"] == 0]\n",
    "display(right_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\"eye\",data= in_lbls, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "k6KkkUxUu_3i",
    "outputId": "04df84e8-7677-4fdd-d2bb-dbc59993357b"
   },
   "outputs": [],
   "source": [
    "sns.countplot(\"level\",data= left_lbls, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dD7Yqd4Q8Sw"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Trimming*:  \n",
    "\n",
    "    Converts image to grayscale using cv2, then computes binary matrix\n",
    "    of the pixels that are above a certain threshold, then takes out\n",
    "    the first row where a certain percetage of the pixels are above the\n",
    "    threshold will be the first clip point. Same idea for col, max row, max col.\n",
    "\n",
    "*resize_maintain_aspect*:   \n",
    "\n",
    "    Resizes the image by padding black pixels to preserve aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(im):\n",
    "\n",
    "    percentage = 0.02\n",
    "\n",
    "    img = np.array(im)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "    row_sums = np.sum(im, axis=1)\n",
    "    col_sums = np.sum(im, axis=0)\n",
    "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "    min_row, min_col = np.min(rows), np.min(cols)\n",
    "    max_row, max_col = np.max(rows), np.max(cols)\n",
    "    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n",
    "    return Image.fromarray(im_crop)\n",
    "\n",
    "\n",
    "def resize_maintain_aspect(image, desired_size):\n",
    "\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.ANTIALIAS)\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n",
    "    return new_im\n",
    "\n",
    "# Used in previous version of implementation but deprecated now\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "    \n",
    "# Used in previous version of implementation but deprecated now\n",
    "def load_ben_color(img, sigmaX=5):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Dataset Preparation\n",
    "\n",
    "Specify the number of samples per class in the variable named *trgt_nbr_samples_per_class*.  \n",
    "Then specify the target *img_width* and *img_height* to resize the images.  \n",
    "N.B: Increasing the image size affects positively on getting a higher accuracy & Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt_nbr_samples_per_class = 10000\n",
    "\n",
    "# Resize params\n",
    "img_width = int(100)\n",
    "img_height = int(100)\n",
    "\n",
    "imgs_left_flat = [] # Resulting dataset for only left images\n",
    "imgs_left_label = [] # Label of left eye images\n",
    "\n",
    "imgs_right_flat = [] # Resulting dataset for only right images\n",
    "imgs_right_label = [] # Label of right eye images\n",
    "\n",
    "\n",
    "# Local variables to check that the number of samples\n",
    "# we're using for our dataset doesn't exceed the trgt_nbr_samples_per_class\n",
    "class_samples = {}\n",
    "class_samples[0] = 0\n",
    "class_samples[1] = 0\n",
    "class_samples[2] = 0\n",
    "class_samples[3] = 0\n",
    "class_samples[4] = 0\n",
    "\n",
    "for image in tqdm(in_imgs_path):\n",
    "    try:\n",
    "        base_folder = os.path.basename(image)\n",
    "        fileName = os.path.splitext(base_folder)[0]\n",
    "        \n",
    "        patient_name = fileName\n",
    "\n",
    "        patient = patient_name.split(\"_\",1)[0]\n",
    "        eye = patient_name.split(\"_\",1)[1]\n",
    "\n",
    "        tmp_lbl = in_lbls.loc[in_lbls.image==fileName, 'level'].values[0] # reference is variable called eye\n",
    "        \n",
    "        \n",
    "        if class_samples[tmp_lbl] < trgt_nbr_samples_per_class:\n",
    "            class_samples[tmp_lbl] = class_samples[tmp_lbl] + 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if(eye == \"left\"):\n",
    "            # Get the left eye and then its associated right eye for the same patient.\n",
    "            im = Image.open(image) \n",
    "            im = trim(im)\n",
    "            im = resize_maintain_aspect(im, desired_size=img_width)\n",
    "            img = im.convert('L')\n",
    "            \n",
    "            imgs_left_label.append(tmp_lbl)\n",
    "            imgs_left_flat.append(np.array(img).flatten())\n",
    "            \n",
    "            # Right eye of same patient\n",
    "            im = Image.open(image.replace(\"left\",\"right\")) \n",
    "            im = trim(im)\n",
    "            im = resize_maintain_aspect(im, desired_size=img_width)\n",
    "            img = im.convert('L')\n",
    "\n",
    "            imgs_right_label.append(tmp_lbl)\n",
    "            imgs_right_flat.append(np.array(img).flatten())\n",
    "        else:\n",
    "            # Get the right eye and then its associated left eye for the same patient.\n",
    "            im = Image.open(image) \n",
    "            im = trim(im)\n",
    "            im = resize_maintain_aspect(im, desired_size=img_width)\n",
    "            img = im.convert('L')\n",
    "\n",
    "            imgs_right_label.append(tmp_lbl)\n",
    "            imgs_right_flat.append(np.array(img).flatten())\n",
    "            \n",
    "            # Left eye of same patient\n",
    "            im = Image.open(image.replace(\"right\",\"left\")) \n",
    "            im = trim(im)\n",
    "            im = resize_maintain_aspect(im, desired_size=img_width)\n",
    "            img = im.convert('L')\n",
    "            \n",
    "\n",
    "            imgs_left_label.append(tmp_lbl)\n",
    "            imgs_left_flat.append(np.array(img).flatten())\n",
    "        \n",
    "        \n",
    "      \n",
    "    except:\n",
    "        continue;\n",
    "        #print(\"Exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls_bincount = np.bincount(imgs_left_label)\n",
    "print(lvls_bincount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSAbemlORDJ_",
    "outputId": "293e18f5-7f69-4656-982a-61b63f980f27"
   },
   "outputs": [],
   "source": [
    "lvls_bincount = np.bincount(imgs_right_label)\n",
    "print(lvls_bincount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xFiv_XYkhqw",
    "outputId": "eaa7a208-d59f-4300-ddf7-5dbc28c5e06b"
   },
   "outputs": [],
   "source": [
    "print(len(imgs_left_label))\n",
    "print(len(imgs_left_flat))\n",
    "\n",
    "print(len(imgs_right_label))\n",
    "print(len(imgs_right_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and Dataset Balancing\n",
    "Augment the data to have equal number of samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm1mrUxWMeLY"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range = (0.5, 1.2),\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChaLLJw2axvQ"
   },
   "outputs": [],
   "source": [
    "def getRand_Left_ImgFromClass(classIndex):\n",
    "    values = np.array(imgs_left_label)\n",
    "    searchval = classIndex\n",
    "    indeces = np.where(values == searchval)[0]\n",
    "    index = np.random.choice(indeces, 1, replace=False)\n",
    "    return index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRand_Right_ImgFromClass(classIndex):\n",
    "    values = np.array(imgs_right_label)\n",
    "    searchval = classIndex\n",
    "    indeces = np.where(values == searchval)[0]\n",
    "    index = np.random.choice(indeces, 1, replace=False)\n",
    "    return index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htOKHthkd_O1"
   },
   "outputs": [],
   "source": [
    "def generateSamples(x, nbrOfSamples):\n",
    "    samples = []\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1):\n",
    "        augImage = batch[0]\n",
    "        augImage = augImage.astype('float32')\n",
    "        augImage /= 255\n",
    "        samples.append(augImage.flatten())\n",
    "        i += 1\n",
    "        if i > (nbrOfSamples - 1):\n",
    "            return samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check a resulting image sample for right eye\n",
    "i = 0\n",
    "indx = getRand_Right_ImgFromClass(i)\n",
    "img = imgs_right_flat[indx]\n",
    "img = img.reshape((img_width,img_width,1))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "ahq_D5xSSvE0",
    "outputId": "559f8265-a6b4-48f7-9bfb-cf5570932013",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test to check a resulting image sample for left eye\n",
    "i = 0\n",
    "indx = getRand_Left_ImgFromClass(i)\n",
    "img = imgs_left_flat[indx]\n",
    "img = img.reshape((img_width,img_width,1))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating all previous parts together to generate new samples for left and right eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw8lIYrqS_XV"
   },
   "outputs": [],
   "source": [
    "# Left eye\n",
    "print(\"Generating Left Images\")\n",
    "nbSamples = 5 # Specifies number of new augmented data samples to be generated given one \"good\" initial sample\n",
    "lvls_bincount = np.bincount(imgs_left_label)\n",
    "for classIndex,count in enumerate(lvls_bincount):\n",
    "    if count < trgt_nbr_samples_per_class:\n",
    "        print(classIndex)\n",
    "        nb_imgs_to_gnrt = trgt_nbr_samples_per_class - count\n",
    "        for i in range(int(nb_imgs_to_gnrt/nbSamples)):\n",
    "            # Get rand image for this classIndex\n",
    "            indx = getRand_Left_ImgFromClass(classIndex)\n",
    "            img = imgs_left_flat[indx]\n",
    "            img = img.reshape((img_width,img_width,1))\n",
    "            x = img_to_array(img)  # this is a Numpy array with shape (3, img_height, img_width)\n",
    "            x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, img_height, img_width)\n",
    "            samples = generateSamples(x,nbSamples)\n",
    "            for j in range(nbSamples):\n",
    "                imgs_left_flat.append(samples[j])\n",
    "                imgs_left_label.append(classIndex)\n",
    "\n",
    "# Right eye\n",
    "print(\"Generating Right Images\")\n",
    "nbSamples = 5 # Specifies number of new augmented data samples to be generated given one \"good\" initial sample\n",
    "lvls_bincount = np.bincount(imgs_right_label)\n",
    "for classIndex,count in enumerate(lvls_bincount):\n",
    "    if count < trgt_nbr_samples_per_class:\n",
    "        print(classIndex)\n",
    "        nb_imgs_to_gnrt = trgt_nbr_samples_per_class - count\n",
    "        for i in range(int(nb_imgs_to_gnrt/nbSamples)):\n",
    "            # Get rand image for this classIndex\n",
    "            indx = getRand_Right_ImgFromClass(classIndex)\n",
    "            img = imgs_right_flat[indx]\n",
    "            img = img.reshape((img_width,img_width,1))\n",
    "            x = img_to_array(img)  # this is a Numpy array with shape (3, img_height, img_width)\n",
    "            x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, img_height, img_width)\n",
    "            samples = generateSamples(x,nbSamples)\n",
    "            for j in range(nbSamples):\n",
    "                imgs_right_flat.append(samples[j])\n",
    "                imgs_right_label.append(classIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset split for Left and Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtBeq0qMiw4i",
    "outputId": "9e277489-af7a-493b-848d-d99f085de66e"
   },
   "outputs": [],
   "source": [
    "# Dataset of Left Images\n",
    "\n",
    "imgs_left_flat = np.asarray(imgs_left_flat)\n",
    "imgs_left_label = np.asarray(imgs_left_label)\n",
    "\n",
    "X_left = imgs_left_flat\n",
    "y_left = imgs_left_label\n",
    "\n",
    "X_train_left, X_test_left, y_train_left, y_test_left = train_test_split(X_left, y_left, test_size=0.3, random_state=5)\n",
    "\n",
    "X_train_left = X_train_left.reshape(X_train_left.shape[0], img_width, img_height,1) # add ,3 if RGB\n",
    "X_test_left = X_test_left.reshape(X_test_left.shape[0], img_width, img_height,1)  # add ,3 if RGB\n",
    "\n",
    "\n",
    "X_train_left = X_train_left.astype('float32')\n",
    "X_test_left = X_test_left.astype('float32')\n",
    "\n",
    "X_train_left /= 255\n",
    "X_test_left /= 255\n",
    "\n",
    "\n",
    "print(X_train_left.shape)\n",
    "print(y_train_left.shape)\n",
    "print(X_test_left.shape)\n",
    "print(y_test_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of Right Images\n",
    "\n",
    "imgs_right_flat = np.asarray(imgs_right_flat)\n",
    "imgs_right_label = np.asarray(imgs_right_label)\n",
    "\n",
    "X_right = imgs_right_flat\n",
    "y_right = imgs_right_label\n",
    "\n",
    "X_train_right, X_test_right, y_train_right, y_test_right = train_test_split(X_right, y_right, test_size=0.9998, random_state=5)\n",
    "\n",
    "X_train_right = X_train_right.reshape(X_train_right.shape[0], img_width, img_height,1) # add ,3 if RGB\n",
    "X_test_right = X_test_right.reshape(X_test_right.shape[0], img_width, img_height,1)  # add ,3 if RGB\n",
    "\n",
    "X_train_right = X_train_right.astype('float32')\n",
    "X_test_right = X_test_right.astype('float32')\n",
    "\n",
    "X_train_right /= 255\n",
    "X_test_right /= 255\n",
    "\n",
    "\n",
    "print(X_train_right.shape)\n",
    "print(y_train_right.shape)\n",
    "print(X_test_right.shape)\n",
    "print(y_test_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmY54R0pisp9"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "nb_classes = 5\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8xZc98IjBPZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_left = to_categorical(y_train_left, nb_classes)\n",
    "y_test_left = to_categorical(y_test_left, nb_classes)\n",
    "\n",
    "y_train_right = to_categorical(y_train_right, nb_classes)\n",
    "y_test_right = to_categorical(y_test_right, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLclgMCIzOhY"
   },
   "outputs": [],
   "source": [
    "c = [np.argmax(row) for row in y_train_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "f6hqyQ8djB7c",
    "outputId": "2d9f33d3-b109-40ae-fbf8-add46482506c"
   },
   "outputs": [],
   "source": [
    "training_bincount = np.bincount(c)\n",
    "print(training_bincount)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax_labels = [0,1,2,3,4]\n",
    "ax_data = training_bincount\n",
    "ax.bar(ax_labels,ax_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Kappa Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_kappa(actuals, preds, N=5):\n",
    "    \"\"\"This function calculates the Quadratic Kappa Metric used for Evaluation at Kaggle.\n",
    "    It returns the Quadratic Weighted Kappa metric score between the actual and the predicted values.\"\"\"\n",
    "    w = np.zeros((N,N))\n",
    "    O = confusion_matrix(actuals, preds)\n",
    "    for i in range(len(w)): \n",
    "        for j in range(len(w)):\n",
    "            w[i][j] = float(((i-j)**2)/(N-1)**2)\n",
    "    \n",
    "    act_hist=np.zeros([N])\n",
    "    for item in actuals: \n",
    "        act_hist[item]+=1\n",
    "    \n",
    "    pred_hist=np.zeros([N])\n",
    "    for item in preds: \n",
    "        pred_hist[item]+=1\n",
    "                         \n",
    "    E = np.outer(act_hist, pred_hist);\n",
    "    E = E/E.sum();\n",
    "    O = O/O.sum();\n",
    "    \n",
    "    num=0\n",
    "    den=0\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w)):\n",
    "            num+=w[i][j]*O[i][j]\n",
    "            den+=w[i][j]*E[i][j]\n",
    "    return (1 - (num/den))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining two Bayesian CNNs\n",
    "One used for left eye images only and another user for right eye images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UIUUDldj0sp",
    "outputId": "95369736-29f8-4952-86a7-de3ac185d887"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "# Left eye model\n",
    "\n",
    "model_in = tf.keras.layers.Input(shape=(img_width,img_height,1))\n",
    "\n",
    "conv_1 = tfp.python.layers.Convolution2DFlipout(32, kernel_size=(5, 5), padding=\"same\", strides=2)\n",
    "x = conv_1(model_in)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "conv_2 = tfp.python.layers.Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "x = conv_2(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "conv_3 = tfp.python.layers.Convolution2DFlipout(128, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "x = conv_3(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "dense_1 = tfp.python.layers.DenseFlipout(2000, activation='relu')\n",
    "x = dense_1(x)\n",
    "\n",
    "dense_2 = tfp.python.layers.DenseFlipout(nb_classes, activation='softmax')\n",
    "model_out = dense_2(x)  \n",
    "\n",
    "model = tf.keras.Model(model_in, model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# Right eye model\n",
    "\n",
    "model_in_r = tf.keras.layers.Input(shape=(img_width,img_height,1))\n",
    "\n",
    "conv_1_r = tfp.python.layers.Convolution2DFlipout(32, kernel_size=(5, 5), padding=\"same\", strides=2)\n",
    "x = conv_1_r(model_in_r)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "conv_2_r = tfp.python.layers.Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "x = conv_2_r(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "conv_3_r = tfp.python.layers.Convolution2DFlipout(128, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "x = conv_3_r(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "dense_1_r = tfp.python.layers.DenseFlipout(2000, activation='relu')\n",
    "x = dense_1(x)\n",
    "\n",
    "dense_2_r = tfp.python.layers.DenseFlipout(nb_classes, activation='softmax')\n",
    "model_out_r = dense_2_r(x)  \n",
    "\n",
    "model_right = tf.keras.Model(model_in_r, model_out_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence lower bound loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42vBA4TlkgZP"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def elbo_loss(labels, logits):\n",
    "    loss_en = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "    loss_kl = tf.keras.losses.KLD(labels, logits)\n",
    "    loss = tf.reduce_mean(tf.add(loss_en, loss_kl))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training step for right and left models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_Bh55lyvS4Z"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_left(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(X_train_left)\n",
    "        loss = elbo_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def train_step_right(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model_right(X_train_right)\n",
    "        loss = elbo_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, model_right.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model_right.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return np.mean(np.argmax(preds, axis=1) == np.argmax(labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ3LWNImvVpE"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training + evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYypQseHvXoM",
    "outputId": "b513b948-3e62-4692-b69f-ea7f26213de8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "times = [] # Stores how much time each training loop took\n",
    "accs = [] # Stores training accuracy at every epoch\n",
    "val_accs = [] # Stores validation accuracy at every epoch\n",
    "losses = [] # loss per epoch\n",
    "val_losses = [] # val_loss per epoch\n",
    "\n",
    "for i in range(epochs):\n",
    "    tic = time.time()\n",
    "    loss = train_step_left(X_train_left, y_train_left)\n",
    "    preds = model(X_train_left)\n",
    "    acc = accuracy(preds, y_train_left)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_preds = model(X_test_left)\n",
    "    val_loss = elbo_loss(y_test_left, val_preds)\n",
    "    val_acc = accuracy(y_test_left, val_preds)\n",
    "    \n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    tac = time.time()\n",
    "    train_time = tac-tic\n",
    "    times.append(train_time)\n",
    "\n",
    "    \n",
    "    print(\"Epoch: {}: loss = {:7.3f} , accuracy = {:7.3f}, val_loss = {:7.3f}, val_acc={:7.3f} time: {:7.3f}\".format(i, loss, acc, val_loss, val_acc, train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(accs), label=\"acc\")\n",
    "plt.plot(np.array(val_accs), label=\"val_acc\")\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.array(losses), label=\"loss\")\n",
    "plt.plot(np.array(val_losses), label=\"val_loss\")\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "preds = model.predict(X_test_left, batch_size = 32, verbose = 0)\n",
    "preds_out = np.argmax(preds, -1)\n",
    "y_test_out = np.argmax(y_test_left, -1)\n",
    "print('Accuracy on Test Data: %2.2f%%' % (accuracy_score(y_test_out, preds_out)))\n",
    "print(classification_report(y_test_out, preds_out))\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(labels,preds):\n",
    "        cm = metrics.confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "        plt.title('Confusion matrix', size = 15)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(5)\n",
    "        plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\",\"4\"], rotation=0, size = 10)\n",
    "        plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\",\"4\"], size = 10)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('Actual label', size = 15)\n",
    "        plt.xlabel('Predicted label', size = 15)\n",
    "        width, height = cm.shape \n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                plt.annotate(str(cm[x][y]), xy=(y, x), horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "plot_confusion_matrix(y_test_out,preds_out)\n",
    "quadratic_kappa(y_test_out, preds_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "times = [] # Stores how much time each training loop took\n",
    "accs = [] # Stores training accuracy at every epoch\n",
    "val_accs = [] # Stores validation accuracy at every epoch\n",
    "losses = [] # loss per epoch\n",
    "val_losses = [] # val_loss per epoch\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    tic = time.time()\n",
    "    loss = train_step_right(X_train_right, y_train_right)\n",
    "    preds = model_right(X_train_right)\n",
    "    acc = accuracy(preds, y_train_right)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_preds = model_right(X_test_right)\n",
    "    val_loss = elbo_loss(y_test_right, val_preds)\n",
    "    val_acc = accuracy(y_test_right, val_preds)\n",
    "    \n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "   \n",
    "    tac = time.time()\n",
    "    train_time = tac-tic\n",
    "    times.append(train_time)\n",
    "    \n",
    "    print(\"Epoch: {}: loss = {:7.3f} , accuracy = {:7.3f}, val_loss = {:7.3f}, val_acc={:7.3f} time: {:7.3f}\".format(i, loss, acc, val_loss, val_acc, train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(accs), label=\"acc\")\n",
    "plt.plot(np.array(val_accs), label=\"val_acc\")\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.array(losses), label=\"loss\")\n",
    "plt.plot(np.array(val_losses), label=\"val_loss\")\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "preds = model_right.predict(X_test_right, batch_size = 32, verbose = 0)\n",
    "preds_out = np.argmax(preds, -1)\n",
    "y_test_out = np.argmax(y_test_right, -1)\n",
    "print('Accuracy on Test Data: %2.2f%%' % (accuracy_score(y_test_out, preds_out)))\n",
    "print(classification_report(y_test_out, preds_out))\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(labels,preds):\n",
    "        cm = metrics.confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "        plt.title('Confusion matrix', size = 15)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(5)\n",
    "        plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\",\"4\"], rotation=0, size = 10)\n",
    "        plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\",\"4\"], size = 10)\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('Actual label', size = 15)\n",
    "        plt.xlabel('Predicted label', size = 15)\n",
    "        width, height = cm.shape \n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                plt.annotate(str(cm[x][y]), xy=(y, x), horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "plot_confusion_matrix(y_test_out,preds_out)\n",
    "quadratic_kappa(y_test_out, preds_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving / Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right model\n",
    "# model_right.save('./models/right/right_eye2')\n",
    "# model_right = tf.keras.models.load_model(\"./models/right/right_eye\")\n",
    "\n",
    "# Left model\n",
    "# model.save('./models/left/left_eye2')\n",
    "# model_left = tf.keras.models.load_model(\"./models/left/left_eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using the two models (taking into consideration the uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_l = X_left.reshape(X_left.shape[0], img_width, img_height,1) # add ,3 if RGB\n",
    "x_r = X_right.reshape(X_right.shape[0], img_width, img_height,1) # add ,3 if RGB\n",
    "\n",
    "y_l = y_left\n",
    "y_r = y_right\n",
    "\n",
    "print(X_test_right.shape)\n",
    "print(x_l[7000:10000].shape)\n",
    "print(x_r[7000:10000].shape)\n",
    "\n",
    "\n",
    "print(y_l[7000:10000].shape)\n",
    "print(y_r[7000:10000].shape)\n",
    "\n",
    "print(y_r[7000:10000].shape)\n",
    "accuracy_score(y_l[7000:10000], y_r[7000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_labels = []\n",
    "\n",
    "# Inference\n",
    "mc_samples = 5\n",
    "preds = [model(X_test_left) for _ in range(mc_samples)]\n",
    "preds = np.concatenate([tf.nn.softmax(y, axis = -1)[:, :, np.newaxis] for y in preds], axis=-1)\n",
    "\n",
    "preds_right = [model_right(X_test_left) for _ in range(mc_samples)]\n",
    "preds_right = np.concatenate([tf.nn.softmax(y, axis = -1)[:, :, np.newaxis] for y in preds_right], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test_left)):\n",
    "    pred_left = preds[i]\n",
    "    mean_left = pred_left.mean(axis=1)\n",
    "    max_left = np.argmax(mean_left)\n",
    "    \n",
    "    pred_right = preds_right[i]\n",
    "    mean_right = pred_right.mean(axis=1)\n",
    "    max_right = np.argmax(mean_right)\n",
    "    \n",
    "    if(max_left > max_right):\n",
    "        out_labels.append(max_left)\n",
    "    else:\n",
    "        out_labels.append(max_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = np.argmax(y_test_left,-1)\n",
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(y_out, out_labels)))\n",
    "print(\"Kappa: \" + str(quadratic_kappa(y_out, out_labels)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Frequentist CNN for DR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
